{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install all required packages if not already installed\n",
                "!pip install pandas matplotlib seaborn scikit-learn -q"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the dataset\n",
                "car_df = pd.read_csv('global_cars_enhanced.csv')\n",
                "\n",
                "# Display first few rows\n",
                "print('First 5 rows:')\n",
                "print(car_df.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check for missing values\n",
                "print('Missing values:')\n",
                "print(car_df.isnull().sum())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Summary statistics\n",
                "print('Summary statistics:')\n",
                "print(car_df.describe())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize Price_Category distribution\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.countplot(x='Price_Category', data=car_df)\n",
                "plt.title('Distribution of Car Price Category')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preprocessing\n",
                "# Drop Car_ID column (not useful for classification)\n",
                "car_df = car_df.drop('Car_ID', axis=1)\n",
                "\n",
                "# Drop Price_USD column (we are predicting Price_Category, so Price would leak the target)\n",
                "if 'Price_USD' in car_df.columns:\n",
                "    car_df = car_df.drop('Price_USD', axis=1)\n",
                "\n",
                "# Encode all remaining categorical (object) columns using LabelEncoder\n",
                "label_encoders = {}\n",
                "for col in car_df.select_dtypes(include=['object']).columns:\n",
                "    if col == 'Price_Category':\n",
                "        continue  # Skip target column\n",
                "    le = LabelEncoder()\n",
                "    car_df[col] = le.fit_transform(car_df[col])\n",
                "    label_encoders[col] = le\n",
                "    print(f'Encoded column: {col}')\n",
                "\n",
                "print('\\nDataFrame after encoding:')\n",
                "print(car_df.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define features (X) and target (y)\n",
                "X = car_df.drop('Price_Category', axis=1)\n",
                "y = car_df['Price_Category']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split data into training and testing sets\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "# Scale features\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "print(f'X_train shape: {X_train_scaled.shape}')\n",
                "print(f'X_test shape: {X_test_scaled.shape}')\n",
                "print(f'y_train shape: {y_train.shape}')\n",
                "print(f'y_test shape: {y_test.shape}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create and train Logistic Regression model\n",
                "# Using 'lbfgs' solver with increased max_iter for convergence\n",
                "log_reg = LogisticRegression(\n",
                "    multi_class='multinomial',  # For multi-class classification\n",
                "    solver='lbfgs',\n",
                "    max_iter=1000,\n",
                "    random_state=42\n",
                ")\n",
                "# Fit the model on training data\n",
                "log_reg.fit(X_train_scaled, y_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Make predictions on test data\n",
                "y_pred = log_reg.predict(X_test_scaled)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate the model\n",
                "print(\"=\"*50)\n",
                "print(\"LOGISTIC REGRESSION CLASSIFICATION RESULTS\")\n",
                "print(\"=\"*50)\n",
                "# Accuracy\n",
                "accuracy = accuracy_score(y_test, y_pred)\n",
                "print(f\"\\nAccuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
                "# Classification Report\n",
                "print(\"\\nClassification Report:\")\n",
                "print(classification_report(y_test, y_pred))\n",
                "# Confusion Matrix\n",
                "print(\"\\nConfusion Matrix:\")\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "print(cm)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize Confusion Matrix\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
                "            xticklabels=log_reg.classes_,\n",
                "            yticklabels=log_reg.classes_)\n",
                "plt.title('Confusion Matrix - Logistic Regression')\n",
                "plt.xlabel('Predicted')\n",
                "plt.ylabel('Actual')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get prediction probabilities\n",
                "y_pred_proba = log_reg.predict_proba(X_test_scaled)\n",
                "print(\"\\nSample prediction probabilities (first 5):\")\n",
                "print(y_pred_proba[:5])\n",
                "# Feature importance (coefficients)\n",
                "print(\"\\nFeature Coefficients (Importance):\")\n",
                "feature_names = X.columns.tolist()\n",
                "for i, class_name in enumerate(log_reg.classes_):\n",
                "    print(f\"\\n{str(class_name).upper()} class:\")\n",
                "    for feature, coef in sorted(zip(feature_names, log_reg.coef_[i]),\n",
                "                                 key=lambda x: abs(x[1]), reverse=True):\n",
                "        print(f\"  {feature}: {coef:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import Decision Tree Classifier and evaluation metrics\n",
                "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Create and train Decision Tree Classifier\n",
                "dt_classifier = DecisionTreeClassifier(\n",
                "    criterion='gini',      # Split criterion: 'gini' or 'entropy'\n",
                "    max_depth=10,          # Maximum depth of the tree (prevents overfitting)\n",
                "    min_samples_split=10,  # Minimum samples required to split a node\n",
                "    min_samples_leaf=5,    # Minimum samples required at a leaf node\n",
                "    random_state=42\n",
                ")\n",
                "# Fit the model on training data\n",
                "dt_classifier.fit(X_train_scaled, y_train)\n",
                "# Make predictions on test data\n",
                "y_pred_dt = dt_classifier.predict(X_test_scaled)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate the Decision Tree model\n",
                "print(\"=\"*50)\n",
                "print(\"DECISION TREE CLASSIFICATION RESULTS\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
                "print(f\"\\nAccuracy: {accuracy_dt:.4f} ({accuracy_dt*100:.2f}%)\")\n",
                "print(\"\\nClassification Report:\")\n",
                "print(classification_report(y_test, y_pred_dt))\n",
                "\n",
                "print(\"\\nConfusion Matrix:\")\n",
                "cm_dt = confusion_matrix(y_test, y_pred_dt)\n",
                "print(cm_dt)\n",
                "\n",
                "# Visualize Confusion Matrix\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Greens',\n",
                "            xticklabels=dt_classifier.classes_,\n",
                "            yticklabels=dt_classifier.classes_)\n",
                "plt.title('Confusion Matrix - Decision Tree')\n",
                "plt.xlabel('Predicted')\n",
                "plt.ylabel('Actual')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize the Decision Tree (limited depth for readability)\n",
                "plt.figure(figsize=(30, 15))\n",
                "plot_tree(dt_classifier,\n",
                "          feature_names=feature_names,\n",
                "          class_names=[str(c) for c in dt_classifier.classes_],\n",
                "          filled=True,\n",
                "          rounded=True,\n",
                "          max_depth=3,\n",
                "          fontsize=10)\n",
                "plt.title('Decision Tree Visualization (max_depth=3)')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature importance from Decision Tree\n",
                "print(\"\\nFeature Importance (Decision Tree):\")\n",
                "for feature, importance in sorted(zip(feature_names, dt_classifier.feature_importances_),\n",
                "                                   key=lambda x: x[1], reverse=True):\n",
                "    print(f\"  {feature}: {importance:.4f}\")\n",
                "\n",
                "# Visualize Feature Importances\n",
                "importances = dt_classifier.feature_importances_\n",
                "indices = importances.argsort()[::-1]\n",
                "\n",
                "plt.figure(figsize=(12, 6))\n",
                "plt.title('Feature Importances - Decision Tree')\n",
                "plt.bar(range(len(feature_names)), importances[indices], align='center')\n",
                "plt.xticks(range(len(feature_names)), [feature_names[i] for i in indices], rotation=45, ha='right')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model Comparison Summary\n",
                "print(\"=\"*50)\n",
                "print(\"MODEL COMPARISON SUMMARY\")\n",
                "print(\"=\"*50)\n",
                "print(f\"\\nLogistic Regression Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
                "print(f\"Decision Tree Accuracy:       {accuracy_dt:.4f} ({accuracy_dt*100:.2f}%)\")\n",
                "\n",
                "if accuracy > accuracy_dt:\n",
                "    print(\"\\n=> Logistic Regression performs better on this dataset.\")\n",
                "elif accuracy_dt > accuracy:\n",
                "    print(\"\\n=> Decision Tree performs better on this dataset.\")\n",
                "else:\n",
                "    print(\"\\n=> Both models perform equally on this dataset.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}